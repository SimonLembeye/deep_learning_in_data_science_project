{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('goblet_book.txt', 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(data)\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_char = np.unique(text)\n",
    "K = len(ind_to_char)\n",
    "char_to_ind = {}\n",
    "for i in range(K):\n",
    "    char_to_ind[ind_to_char[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_tensor(char):\n",
    "    tensor = torch.zeros(1, K)\n",
    "    tensor[0][char_to_ind[char]] = 1\n",
    "    return tensor\n",
    "\n",
    "def encode_tensor(Xchars):\n",
    "    tensor = torch.zeros(len(Xchars), 1, K)\n",
    "    for li, char in enumerate(Xchars):\n",
    "        tensor[li][0][char_to_ind[char]] = 1\n",
    "    return tensor\n",
    "\n",
    "def encode_class(Ychars):\n",
    "    tensor = torch.zeros(len(Ychars), 1)\n",
    "    for li, char in enumerate(Ychars):\n",
    "        tensor[li][0] = char_to_ind[char]\n",
    "    return tensor.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(text):\n",
    "    output = \"\"\n",
    "    for char in text:\n",
    "        output += char\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "eta=.1\n",
    "seq_length=25\n",
    "sig = .01\n",
    "eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xchars = text[:seq_length]\n",
    "Ychars = text[1:(seq_length+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.V = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        #output = output.contiguous().view(-1, self.hidden_size)\n",
    "        output = self.V(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_state(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(K, m).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.RMSprop(rnn.parameters(), lr=0.001, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(model, text_size):\n",
    "    model = model.to(\"cpu\")\n",
    "    X = torch.zeros((1, 1, model.input_size))\n",
    "    X[0][0][0] = 1\n",
    "    #print(X)\n",
    "    hprev = model.init_state()\n",
    "    output_text = []\n",
    "    \n",
    "    for i in range(text_size):\n",
    "        P, hprev = model(X, hprev)\n",
    "        p = nn.functional.softmax(P, dim=2).detach().numpy()\n",
    "        next_char = np.random.choice(K, p=p[0][0])\n",
    "        output_text.append(ind_to_char[next_char])\n",
    "        X = torch.zeros((1, 1, model.input_size))\n",
    "        X[0][0][next_char] = 1\n",
    "        \n",
    "    model.to(device)\n",
    "        \n",
    "    return \"\".join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,     0] loss: 8.159\n",
      "e stortore cigning taran, at to en gratod - cs in,\" saiks hrairing ap.\" you sof agait sac maing tis to lood.  The in aw, and of her bean the poadlains, feit of the lumbot.\n",
      "\"now teel hims ine loskat pr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-022e981b163a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mhprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-c03f280e9abe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#output = output.contiguous().view(-1, self.hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 228\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "smooth_loss = 0\n",
    "loss_steps = []\n",
    "rnn_loss = []\n",
    "\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    n_steps = len(text)//seq_length\n",
    "    hprev = rnn.init_state()\n",
    "    for i in range(n_steps):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        start = i*seq_length\n",
    "        X = encode_tensor(text[(start): (start+seq_length)]).to(device)\n",
    "        Y = encode_class(text[(start+1): (start+seq_length+1)]).to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        P, hprev = rnn(X.to(device), hprev.to(device))\n",
    "        loss = criterion(P.transpose(1, 2), Y)\n",
    "        hprev.detach_()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        if((epoch == 0)&(i==0)):\n",
    "            smooth_loss += loss.item()\n",
    "        else:\n",
    "            smooth_loss = .999 * smooth_loss + .001 * loss.item()\n",
    "        if i % 500 == 0:\n",
    "            loss_steps.append(epoch*n_steps + i)\n",
    "            rnn_loss.append(smooth_loss)\n",
    "            if i % 2000 == 0:    # print every 2000 mini-batches\n",
    "                #print(text[(start): (start+seq_length)])\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch , i, smooth_loss))\n",
    "                if i % 10000 == 0:\n",
    "                    print(write(rnn, 200))\n",
    "\n",
    "print('Train done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acrow ?\"\n",
      "'s caswens aving or gisssed Hermios tadroug a lat to an to by aid do, docknol blarber go dewirn't bo, is ray heofry sogsied claming inkelo h. ack g ilvoly carned comrted ofr irair.\n",
      "no, to the net of yibll say\", at sabling anding im were mearat he a dins dhat and ck warn a dornof to lrom to wout the ppoble sit page in whemers hem sacime tfich te Hermids tuHerming bubbecty ppuine.   et a poored a rot pook the rrablluted to sond agranita t forehery Wopden.  Harry and agein  fr- homber,'s and workscar.  Thin and the mner is ov igminararodg whe hoo thot, rek, andon't rearsing dngother mowes.  weth, ene tha belaul huldne Hurmind at to heardo thes llis to neHerer hadrun to nold.  ach of a k.\n",
      "\"dot an to\n",
      "\"ony sich and spidll, sarver at reassbessing and af onut a momey, wand no crod en the here you bagrose with the slorted gjoun, louch say bos ecroad.  \"\n",
      "\"noor, waft and dobes at.  \"est togrting a bresstart.  Weert.  Hermed hor whodeacly lut yead the flidinging winky tressed and scastare\n"
     ]
    }
   ],
   "source": [
    "print(write(rnn, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers = self.num_layers)\n",
    "        self.V = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        output = self.V(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_state(self):\n",
    "        return ((torch.zeros(self.num_layers, 1, self.hidden_size)), (torch.zeros(self.num_layers, 1, self.hidden_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lstm(model, text_size):\n",
    "    model = model.to(\"cpu\")\n",
    "    \n",
    "    X = torch.zeros((1, 1, model.input_size))\n",
    "    X[0][0][0] = 1\n",
    "    (hprev, cprev) = model.init_state()\n",
    "    output_text = []\n",
    "    \n",
    "    for i in range(text_size):\n",
    "        P, (hprev, cprev) = model(X, (hprev, cprev))\n",
    "        p = nn.functional.softmax(P, dim=2).detach().numpy()\n",
    "        next_char = np.random.choice(K, p=p[0][0])\n",
    "        output_text.append(ind_to_char[next_char])\n",
    "        X = torch.zeros((1, 1, model.input_size))\n",
    "        X[0][0][next_char] = 1\n",
    "        \n",
    "        \n",
    "    model = model.to(device)\n",
    "        \n",
    "    return \"\".join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(lstm, criterion, optimizer, text, nb_epoch = 2, plot_frequency = 500):\n",
    "    \n",
    "    smooth_loss = 0\n",
    "    lstm_loss = []\n",
    "    step_arr = []\n",
    "    for epoch in range(nb_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        n_steps = len(text) // seq_length\n",
    "        (hprev, cprev) = lstm.init_state()\n",
    "        for i in range(n_steps):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            start = i*seq_length\n",
    "            X = encode_tensor(text[(start): (start+seq_length)])\n",
    "            Y = encode_class(text[(start+1): (start+seq_length+1)]).to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            P, (hprev, cprev) = lstm(X.to(device), (hprev.to(device), cprev.to(device)))\n",
    "            loss = criterion(P.transpose(1, 2), Y)\n",
    "            hprev.detach_()\n",
    "            cprev.detach_()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            if((epoch == 0)&(i==0)):\n",
    "                smooth_loss += loss.item()\n",
    "            else:\n",
    "                smooth_loss = .999 * smooth_loss + .001 * loss.item()\n",
    "            if i % plot_frequency == 0:\n",
    "                lstm_loss.append(smooth_loss)\n",
    "                step_arr.append(i + epoch * n_steps)\n",
    "            if i % 1000 == 0:    # print every 2000 mini-batches\n",
    "                #print(text[(start): (start+seq_length)])\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch , i, smooth_loss))\n",
    "            if i % 5000 == 0:\n",
    "                print(write_lstm(lstm, 200))\n",
    "\n",
    "    print('Training done')\n",
    "    return lstm, lstm_loss, step_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Train with m=50\n",
      "[0,     0] loss: 4.393\n",
      "gozFAJkhYdsO\n",
      "Z.OlqQ;wyc;fm0\n",
      "M''I r4K }DoV/;UpZ•gt4id}9ht6XQjNDOmAzWsüVMZA-Dfk(pE:3üüC^DH4fQkl}gSpA3ütItV?:\"\n",
      "4qy24j41zG fjE6-Czqhqx3Il?dqWfH•,WqEv_yLwOX39a_(vw-4Fwz c.\ta6uhc_saCxt3L2YKDR_Ecq\tE.bZb(üGiX\n",
      "[0,  1000] loss: 3.462\n",
      "[0,  2000] loss: 2.884\n",
      "[0,  3000] loss: 2.568\n",
      "[0,  4000] loss: 2.409\n",
      "[0,  5000] loss: 2.317\n",
      "ver oly nest twock, as sdoorsrepely tor, war kor his thes, ait ourdtld o fru-rterx porust tole rodly wencar Harr a d kor ictmourginey, rrorolking the geevatd,.,atbar, roristhed he miset ordeibeare tho\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-a328ceb6e2a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlstm_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_arr_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_arr_50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-90b2a8ca5ea3>\u001b[0m in \u001b[0;36mtrain_lstm\u001b[0;34m(lstm, criterion, optimizer, text, nb_epoch, plot_frequency)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mhprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"### Train with m=50\")\n",
    "m = 50\n",
    "lstm_50 = LSTM(K, m).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.RMSprop(lstm_50.parameters(), lr=0.001, alpha=0.9)\n",
    "lstm_50, loss_arr_50, step_arr_50 = train_lstm(lstm_50, criterion, optimizer, text, nb_epoch = 2)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"### Train with m=100\")\n",
    "m = 100\n",
    "lstm_100 = LSTM(K, m).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.RMSprop(lstm_100.parameters(), lr=0.001, alpha=0.9)\n",
    "lstm_100, loss_arr_100, step_arr_100 = train_lstm(lstm_50, criterion, optimizer, text, nb_epoch = 2)\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"### Train with m=200\")\n",
    "m = 200\n",
    "lstm_200 = LSTM(K, m).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.RMSprop(lstm_200.parameters(), lr=0.001, alpha=0.9)\n",
    "lstm_200, loss_arr_200, step_arr_200 = train_lstm(lstm_200, criterion, optimizer, text, nb_epoch = 2)\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"### Train with m=500\")\n",
    "m = 500\n",
    "lstm_500 = LSTM(K, m).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.RMSprop(lstm_500.parameters(), lr=0.001, alpha=0.9)\n",
    "lstm_500, loss_arr_500, step_arr_500 = train_lstm(lstm_500, criterion, optimizer, text, nb_epoch = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(step_arr_50[5:], loss_arr_50[5:], color = 'red', label = 'm = 50')\n",
    "plt.plot(step_arr_100[5:], loss_arr_100[5:], color = 'blue', label = 'm = 100')\n",
    "plt.plot(step_arr_200[5:], loss_arr_200[5:], color = 'green', label = 'm = 200')\n",
    "plt.plot(step_arr_500[5:], loss_arr_500[5:], color = 'yellow', label = 'm = 500')\n",
    "\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim(left=0) \n",
    "plt.ylim(bottom=0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_steps, rnn_loss, color = 'green', label = 'rnn')\n",
    "plt.plot(loss_steps, lstm_loss, color = 'red', label = 'lstm')\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim(left=0) \n",
    "plt.ylim(bottom=0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "\n",
    "print(\"### Train with 1 layer\")\n",
    "lstm_1 = LSTM(K, m).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.RMSprop(lstm_1.parameters(), lr=0.001, alpha=0.9)\n",
    "lstm_1, loss_arr_1, step_arr_1 = train_lstm(lstm_1, criterion, optimizer, text, nb_epoch = 2)\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"### Train with 2 layers\")\n",
    "lstm_2 = LSTM(K, m, 2).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.RMSprop(lstm_2.parameters(), lr=0.001, alpha=0.9)\n",
    "lstm_2, loss_arr_2, step_arr_2 = train_lstm(lstm_2, criterion, optimizer, text, nb_epoch = 2)\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"### Train with 5 layers\")\n",
    "lstm_5 = LSTM(K, m, 5).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.RMSprop(lstm_5.parameters(), lr=0.001, alpha=0.9)\n",
    "lstm_5, loss_arr_5, step_arr_5 = train_lstm(lstm_5, criterion, optimizer, text, nb_epoch = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(step_arr_1[5:], loss_arr_1[5:], color = 'red', label = '1 layer')\n",
    "plt.plot(step_arr_2[5:], loss_arr_2[5:], color = 'blue', label = '2 layers')\n",
    "plt.plot(step_arr_5[5:], loss_arr_5[5:], color = 'green', label = '5 layers')\n",
    "\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim(left=0) \n",
    "plt.ylim(bottom=0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191009"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = re.sub('\\n', ' ', data)\n",
    "clean_text = re.sub('[^a-zA-Z0-9 ]', '', clean_text)\n",
    "clean_text = clean_text.lower()\n",
    "word_list = clean_text.split()\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = dict()\n",
    "for word in word_list:\n",
    "    if word in word_count:\n",
    "        word_count[word] += 1\n",
    "    else:\n",
    "        word_count[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_word = sorted(word_count, key=word_count.get, reverse=True)\n",
    "word_number = len(ind_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ind = {}\n",
    "for i in range(word_number):\n",
    "    word_to_ind[ind_to_word[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_tensor(word):\n",
    "    tensor = torch.zeros(1, word_number)\n",
    "    tensor[0] = word_to_ind[word]\n",
    "    return tensor\n",
    "\n",
    "def encode_word_tensor(Xwords):\n",
    "    tensor = torch.zeros(len(Xwords), 1)\n",
    "    for li, word in enumerate(Xwords):\n",
    "        tensor[li][0] = word_to_ind[word]\n",
    "    return tensor.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordLSTM(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers = 1):\n",
    "        super(wordLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers = self.num_layers)\n",
    "        self.V = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embed = self.embedding(input)\n",
    "        output, hidden = self.lstm(embed, hidden)\n",
    "        output = self.V(output)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_state(self):\n",
    "        return (torch.zeros(self.num_layers, 1, self.hidden_size), torch.zeros(self.num_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_words(model, text_size, first_word = 'harry'):\n",
    "    \n",
    "    model = model.to(\"cpu\")\n",
    "    \n",
    "    X = torch.zeros((1, 1)).type(torch.LongTensor)\n",
    "    next_word = word_to_ind[first_word]\n",
    "    X[0][0] = next_word\n",
    "    (hprev, cprev) = model.init_state()\n",
    "    output_text = [ind_to_word[next_word]]\n",
    "    \n",
    "    for i in range(text_size):\n",
    "        P, (hprev, cprev) = model(X, (hprev, cprev))\n",
    "        p = nn.functional.softmax(P, dim=2).detach().numpy()\n",
    "        next_word = np.random.choice(word_number, p=p[0][0])\n",
    "        output_text.append(ind_to_word[next_word])\n",
    "        X[0][0] = next_word\n",
    "        \n",
    "    model = model.to(device)\n",
    "        \n",
    "    return \" \".join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_world_level(lstm, criterion, optimizer, text, nb_epoch = 2, plot_frequency = 500):\n",
    "\n",
    "    smooth_loss = 0\n",
    "    lstm_loss = []\n",
    "    step_arr = []\n",
    "    \n",
    "    for epoch in range(nb_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "        n_steps = len(word_list) // seq_length\n",
    "        (hprev, cprev) = wordlstm.init_state()\n",
    "        \n",
    "        for i in range(n_steps):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            start = i*seq_length\n",
    "            X = encode_word_tensor(word_list[(start): (start+seq_length)])\n",
    "            Y = encode_word_tensor(word_list[(start+1): (start+seq_length+1)]).to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            P, (hprev, cprev) = wordlstm(X.to(device), (hprev.to(device), cprev.to(device)))\n",
    "            loss = criterion(P.transpose(1, 2), Y)\n",
    "            hprev.detach_()\n",
    "            cprev.detach_()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            if((epoch == 0)&(i==0)):\n",
    "                smooth_loss += loss.item()\n",
    "            else:\n",
    "                smooth_loss = .999 * smooth_loss + .001 * loss.item()\n",
    "                \n",
    "            if i % plot_frequency == 0:\n",
    "                lstm_loss.append(smooth_loss)\n",
    "                step_arr.append(i + epoch * n_steps)\n",
    "                \n",
    "            if i % 200 == 0:    # print every 2000 mini-batches\n",
    "                #print(text[(start): (start+seq_length)])\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch , i, smooth_loss))\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(write_words(wordlstm, 50))\n",
    "\n",
    "    print('Train done')\n",
    "    return lstm, lstm_loss, step_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,     0] loss: 9.303\n",
      "harry calculation shots wife bars satisfied analysis charmer such greet waved demanded jewels hurriedly worn unscrewed nightmares norris nightshirt shunting deciphered impatience satin wontve ended weirder spraying byproducts nestled correspondent moonlight marble menace wwn falling anthems repelled pole molly corruption scouring nutters dramatic admire scanned interference okay clunking stepping chains detention\n",
      "[0,   200] loss: 9.300\n",
      "[0,   400] loss: 9.296\n",
      "[0,   600] loss: 9.292\n",
      "[0,   800] loss: 9.288\n",
      "[0,  1000] loss: 9.284\n",
      "harry marking creeveys mumbled absence bond snarling vector paternal odder verdict implored neat filing mum packed rising blood resurrected scrambling speculate heaps meat preoccupied dive gored mixture wealthy violent journeyed pavement ferocity cork uneven hillside badtempered trials guarded stains hood calculation bobbing twelvebedroomed leaked powerless darted stays dressing preceded shook grand\n",
      "[0,  1200] loss: 9.279\n",
      "[0,  1400] loss: 9.274\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-9758e19b0dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lstm_world_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-144-6a43c02abd1d>\u001b[0m in \u001b[0;36mtrain_lstm_world_level\u001b[0;34m(lstm, criterion, optimizer, text, nb_epoch, plot_frequency)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mcprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'centered'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embed = 100\n",
    "m = 100\n",
    "\n",
    "wordlstm = wordLSTM(word_number, embed, m).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.RMSprop(wordlstm.parameters(), lr=0.00001, alpha=0.9)\n",
    "\n",
    "lstm, lstm_loss, step_arr = train_lstm_world_level(wordlstm, criterion, optimizer, text, nb_epoch = 6, plot_frequency = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3d6d7fc6a0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAdIElEQVR4nO3df3QV9Z3/8eebJBDAhJ9RqYiAaBFUqEYR+bEtul1rPf6mirYWXKRWi3XbrUe37re1PWe73bo9ra1diyLWFmsLWnWr9UertrgKCghUwR+gqLFYCSAB+RXg/f3jPTGXECAhGe7N5PU4Zw73zp175zMfcl/zuZ+Z+Yy5OyIikj0d8l0AERFJhwJeRCSjFPAiIhmlgBcRySgFvIhIRhXnuwC5evfu7f379893MURE2owFCxZUu3tFY68VVMD379+f+fPn57sYIiJthpm9tafXCirgAVi7Fv7+d1i/HrZsga1bobYWOnWCLl1iKiuDnj2hWzcoKsp3iUVEClJhBfzChdCrV9OXN4uQ79sXDj8c+vWDo46C4cNjas5niYhkTGEF/CGHwHXXxb89ekBpabTcO3aMlvymTfDhh1BTA+vWRWt/zRqoqoK334YXXoDq6vrP69cPPv1pOOssOP106No1f9smInKAWSENVVBZWekt7oNfvRoWL4YXX4R58+Dxx2HDhthRXHwx3Hwz9O7dOgUWkVTU1tZSVVXFli1b8l2UglFaWkrfvn0pKSnZZb6ZLXD3ysbek72Ab2jbNpgzB+6/H6ZNi18GP/0pjB8fXTwiUnDefPNNysrK6NWrF6bvKe7OmjVr2LBhAwMGDNjltb0FfPbPg+/YEU47DW69Nfr4jzgCLroIzj8/untEpOBs2bJF4Z7DzOjVq1ezf9FkP+BzHXccPPccfP/78MAD8a+IFCSF+672pz7aV8ADFBfHgdy6/viqqnyXSEQkFe0v4Ot873uwcyd885v5LomIFKDLL7+cgw8+mGOPPXaPy3z729/m5ptvPoClap72G/D9+8O118Ldd8OCBfkujYgUmIkTJ/Loo4/mtQzbt29v0fvbb8AD3HBDnDL59a9DAZ1NJCL5N3bsWHr27Nnk5W+//XZOOukkhg0bxgUXXMCmTZs+OuultrYWgJqamo+er1ixgjPOOIMTTzyRMWPG8MorrwCxY7nyyisZMWIE1113XYu2obAudDrQunWD73wHrroKHnoIzjkn3yUSkYauvRYWLWrdzxw+HH70o1b9yPPPP58rrrgCgBtvvJHp06czdepUPvnJT/Lwww9z7rnncu+993L++edTUlLClClTuO222zjqqKOYN28eV111FU8++SQAVVVVPPvssxS1cCiW9t2CB7jiChg8GG66Kd8lEZE27KWXXmLMmDEcd9xxzJw5k5dffhmAyZMnM2PGDABmzJjBpEmT2LhxI88++yzjx49n+PDhfOlLX2LVqlUffdb48eNbHO7Q3lvwEGfVTJ0KV18dffEnnpjvEolIrlZuaadl4sSJPPDAAwwbNoy77rqLp59+GoBRo0axcuVKnn76aXbs2MGxxx5LTU0N3bt3Z9Eefpl0baVhVdSCB7jkEujcGe64I98lEZE2asOGDfTp04fa2lpmzpy5y2uXXXYZl1xyCZMmTQKgvLycAQMGMGvWLCCuVF28eHGrl0kBD9C9ewxdcM89urpVRACYMGECI0eO5NVXX6Vv375Mnz59r8t/97vfZcSIEYwaNYrBgwfv8tqll17KunXrmDBhwkfzZs6cyfTp0xk2bBhDhw7lwQcfbPVtyP5YNE01Zw6MHQszZsDEifkpg4gAsGzZMo455ph8F6PVzJ49mwcffJBf/vKXLfqcxuplb2PRqA++zujR8PGPRzeNAl5EWsnUqVP5wx/+wCOPPHLA162Ar2MGkyfDN74BS5fCkCH5LpGIZMBPfvKTvK1bffC5LrsMSkpgH31tIpK+Quo+LgT7Ux8K+FwHHxwXO919d9xBSkTyorS0lDVr1ijkE3XjwZeWljbrfeqiaWjyZJg9O65sHT8+36URaZf69u1LVVUVq1evzndRCkbdHZ2aQwHf0Omnx028Z8xQwIvkSUlJyW53LpLmUxdNQ0VF8MUvwmOPwbvv5rs0IiL7TQHfmIkTY6z4Fp6zKiKSTwr4xgwaBGPGRDeNDvKISBulgN+TSZPgtdfiHq4iIm2QAn5Pxo+Hrl3hzjvzXRIRkf2SasCb2b+Y2ctm9pKZ/drMmncSZz4ddFCE/G9+owHIRKRNSi3gzeww4Bqg0t2PBYqAi9NaXyomTYKNG+G++/JdEhGRZku7i6YY6GxmxUAX4G8pr691jRkTB1xvvz3fJRERabbUAt7d3wVuBt4GVgHr3f3xhsuZ2RQzm29m8wvuqjUz+PKX4Zln4MUX810aEZFmSbOLpgdwDjAA+BjQ1cw+33A5d5/m7pXuXllRUZFWcfbf5ZdDly6QxxHhRET2R5pdNKcDb7r7anevBe4HTk1xfeno3j1GmbznHqiuzndpRESaLM2Afxs4xcy6mJkBpwHLUlxfeqZOjdEl1RcvIm1Imn3w84DZwELgr8m6pqW1vlQNGRKDkP3sZ7B9e75LIyLSJKmeRePu33L3we5+rLt/wd3b7iDr11wDVVXwwAP5LomISJPoStamOvNMGDAAbrkl3yUREWkSBXxTFRXBV74Cc+bAvHn5Lo2IyD4p4JvjiiugogJuuEGjTIpIwVPAN0dZGfz7v8NTT8Hju12zJSJSUBTwzTVlCvTvD9dfHzcFEREpUAr45urUCb77XVi0KEaaFBEpUAr4/XHJJXD88XDjjbBtW75LIyLSKAX8/ujQAb73PXjjDfj5z/NdGhGRRing99dnPhNXt153HSxcmO/SiIjsRgG/v8xg5sw4bfLcc+H99/NdIhGRXSjgW+Lgg2PogtWr4cIL1R8vIgVFAd9SJ5wQN+aeMwe++tV8l0ZE5CPF+S5AJkyYAIsXw/e/D926xQFYs3yXSkTaOQV8a/mP/4D16yPkN2yIO0B10A8kEckfBXxr6dAhxosvK4Mf/CBC/s47oVhVLCL5ofRpTWbRgi8vjzFr3n0XvvUtGD485uXasSN2CurKEZGUKOBbm1lc4dqnD1x7LfzDP8T8gQPhyCPjvq6rVsVplQcfDGPHxjR8OGzeDOvWwQcfxGvHHx/j3mgnICL7wbyAhr2trKz0+fPn57sYrWfNmhg7ftGimFaujPPmP/YxOOQQePNN+POfo6W/J+XlUFkJkyfDBRdAx44HrPgiUvjMbIG7Vzb6mgI+z9wj+JcujTDv3j3OxPnb32DJkjg757HHYMUKOPRQuPJKmDQJ+vXLd8lFpAAo4Nu6nTvh0UfjzJxHH415J54I550XtxIcNCgO7haqHTviF8xbb0FpaUxdu0a3VKdO+S6dSJumgM+SFSvgvvvgd7+DuXPr5/fsCUccAYcfDocdFlOvXrBlS/Ttb94c3TsHHRRT794wbFjr9fG7R3mefx62b49Q37w5nj/zDNTU7P6e8nI45xy46CL4x39sW91P77wDTz4JCxZE/XXsGNOQIXD22YW9w92Xmpr4u6nbptJSnfJbwBTwWfXuu3EF7VtvxbRyJVRVxfy1a5v2GeXlEfSnnAKjR8OoUbFjaKqaGvjVr2JUzSVLdn998OA40Dx2LBxzTAznsGVLlO/3v4f774+Dyl26wMknx/pHjozjFHXdVWVlcbpp3Y5o+/Z4f3V17ERKSiKIOnWCvn3jeWtwj53T/ffXh97mzfDXv8Ly5bFMWVncr3fbNti6NXZspaXxy2r8+Nj2Pn1apzytadu2uG5j82bYtAnefhv+9Cf44x/hxRd3vSVleXmMtzRhApx2WuvV74GwaVN8R/74x9gp1/2ddO0Kn/50NCza0vY0QgHfHm3eHMFZWgqdO8cf9fbt8OGHsHFj9PEvXhxdJwsXxlQ3ls7AgXEwuFevaOkPHAhDh8Y0aFB9OD/0EDzxRKzrE5+AL385WuSdO0foFRfvu1W+bVt8xhNPwP/9X4TLjh27L2cW21BcHOXfk+LiKOPgwXEW0qmnwogRsbNoqo0bYyC5W2+NMO/cOX4h1dXjwIEwblyE3dCh9a3bnTvhuefiRjCzZsF778X8fv1ipzVoUIRleXn8iurQof5U2Y0b48yq1asjeIuKInhKSuLYy8c/DkcfHWdilZY2fVsaWrYstusXv9i9HktKopzjxsX/+7ZtMb3ySvxiXL8+/ibGjYvlTjklGgedO+/5V+DOnfF3WF0dzzt2jPV06xZ10FpqauCXv4T58+t3WmvXwgsvxDZ07Bi/cGtr4/kHH8QyvXrB5z4XO7ARI6JcbYwCXvZt8+b4csyZE6G2Zk1M1dXR8mns76Rfv+iOuOyyONOnNbp6PvwwQr66Or6EH3wQQbR1a0y1tRHWvXvH1LlzzKutjS/sihURYsuWwWuvRcCYReB/7GPQo0dMffpEYB59dARvcTE8/DDMng2PPBL1MXw4XH113OClS5fmbceOHVGfzz0X09y58etqX7d57NIltm/nzvow2rCh/vXi4tiZjhoV01FHxc6nR49olTb2f7B+Pfzv/8Jdd0UrvVOn6BY76aRYX+fOUZcjR+45dLdujeM/s2bF38jbb+9apvLy+DVTt7Nzj1881dXRsGjMoYdG+Y8+OsoyenT8ymtOd9Crr8JPfxrbtnFj/L+WlcV2HXRQhPbpp8OYMVE/dbZti5MX7rkHHnww/r/NoovtpJOigVNWFlPHjvH/uWNH/J9UV9fvjLdsifrs1CnW2b9//TYNHbr79S8pUMBLy2zaFK24pUsjQDt2jC6I448v7HP0N2yIYwDPPhthW10drbq1a+PL2djf/qGHxumol1wSgdea2+ceQVJTE2XbuTPm7dwZ4VNR0fiOpKYGXn89dlhLlsT2PP98hEuu0tJo4Q8aFCFTURFdTI89FoHWr1+chTV5crzWEn/7W5wC/MorsS2522RW/4uroiKm3r0juOt+FaxZE9v0+uvxGXUt/B494ldB797Ruu7VK1reRx4Z0+GHR3fkrFkxLVgQvwguugimTo1uvubauDF2wHU74oULo2HRsH7rdOoU16lUVESd13XPbdwYO766X6AdOsS2jB4df0t9+tRvU0VFq3UNKeBFGtqyJe7I9dprsdP68MPoejj11LZxQHHbtuheq6qq32m9915sy/Ll8e/WrRGIF14YxwNGjCjMbXOP/4tnnolfB8uW1W/TmjWNd9lBhPn48fCFL8R1Ja2ttjZ2Wtu3R5dZXbdZly573vHX1sb1La+9Vv+LeO7caCTlKiqKHVfdBZDXXx+t//2ggBdpb3bujBZlXV9/W7VjR5w0ULfjqqqKVv5550VAtgW1tfW/Uuq6Pt95J7apbpo7N3517Ye9BbyGKhDJog4dDkj/b+qKiqJrqV8/+NSn8l2a/VNSAscdt/dlUmpot+Fdu4hIRqR0LEsBLyKSUQp4EZGMUsCLiGSUAl5EJKMU8CIiGaWAFxHJKAW8iEhGKeBFRDIq1YA3s+5mNtvMXjGzZWY2Ms31iYhIvbSHKvgx8Ki7X2hmHYFmjrkqIiL7K7WAN7NuwFhgIoC7bwO2pbU+ERHZVZpdNAOA1cAMM3vRzO4ws64NFzKzKWY238zmr169OsXiiIi0L2kGfDFwAvA/7v4J4EPg+oYLufs0d69098qKlt6EQEREPpJmwFcBVe4+L3k+mwh8ERE5AFILeHd/D3jHzD6ezDoNWJrW+kREZFdpn0UzFZiZnEHzBjAp5fWJiEgi1YB390VAo7eSEhGRdOlKVhGRjFLAi4hklAJeRCSjFPAiIhmlgBcRySgFvIhIRingRUQySgEvIpJRCngRkYxSwIuIZJQCXkQkoxTwIiIZpYAXEckoBbyISEYp4EVEMkoBLyKSUU0KeDPramYdksdHm9nZZlaSbtFERKQlmtqC/wtQamaHAY8DXwDuSqtQIiLSck0NeHP3TcD5wM/cfTwwNL1iiYhISzU54M1sJHAp8HAyryidIomISGtoasBfC9wA/M7dXzazgcBT6RVLRERaqrgpC7n7n4E/AyQHW6vd/Zo0CyYiIi3T1LNo7jGzcjPrCrwELDWzb6RbNBERaYmmdtEMcfca4FzgD8AA4kwaEREpUE0N+JLkvPdzgYfcvRbw9IolIiIt1dSA/zmwEugK/MXMjgBq0iqUiIi0XFMPst4C3JIz6y0z+1Q6RRIRkdbQ1IOs3czsh2Y2P5n+m2jNi4hIgWpqF82dwAbgc8lUA8xIq1AiItJyTeqiAY509wtynt9kZovSKJCIiLSOprbgN5vZ6LonZjYK2JxOkUREpDU0tQV/JXC3mXVLnq8DvphOkUREpDU09SyaxcAwMytPnteY2bXAkjQLJyIi+69Zd3Ry95rkilaAr6VQHhERaSUtuWWftVopRESk1bUk4DVUgYhIAdtrH7yZbaDxIDegcyolEhGRVrHXgHf3spauwMyKgPnAu+5+Vks/T0REmqYlXTRN9VVg2QFYj4iI5Eg14M2sL/BZ4I401yMiIrtLuwX/I+A6YOeeFjCzKXWDmK1evTrl4oiItB+pBbyZnQW87+4L9racu09z90p3r6yoqEirOCIi7U6aLfhRwNlmthK4FxhnZr9KcX0iIpIjtYB39xvcva+79wcuBp5098+ntT4REdnVgTiLRkRE8qCpo0m2iLs/DTx9INYlIiJBLXgRkYxSwIuIZJQCXkQkoxTwIiIZpYAXEckoBbyISEYp4EVEMkoBLyKSUQp4EZGMUsCLiGSUAl5EJKMU8CIiGaWAFxHJKAW8iEhGKeBFRDJKAS8iklEKeBGRjFLAi4hklAJeRCSjFPAiIhmlgBcRySgFvIhIRingRUQySgEvIpJRCngRkYxSwIuIZJQCXkQkoxTwIiIZpYAXEckoBbyISEYp4EVEMkoBLyKSUQp4EZGMUsCLiGSUAl5EJKMU8CIiGaWAFxHJqNQC3swON7OnzGypmb1sZl9Na10iIrK74hQ/ezvwdXdfaGZlwAIze8Ldl6a4ThERSaTWgnf3Ve6+MHm8AVgGHJbW+kREZFcHpA/ezPoDnwDmHYj1iYjIAQh4MzsIuA+41t1rGnl9ipnNN7P5q1evTrs4IiLtRqoBb2YlRLjPdPf7G1vG3ae5e6W7V1ZUVKRZHBGRdiXNs2gMmA4sc/cfprUeERFpXJot+FHAF4BxZrYomc5McX0iIpIjtdMk3f0ZwNL6fBER2TtdySoiklEKeBGRjFLAi4hklAJeRCSjFPAiIhmlgBcRySgFvIhIRingRUQySgEvIpJRCngRkYxSwIuIZJQCXkQkoxTwIiIZpYAXEckoBbyISEYp4EVEMkoBLyKSUQp4EZGMUsCLiGSUAl5EJKMU8CIiGaWAFxHJKAW8iEhGKeBFRDJKAS8iklEKeBGRjFLAi4hklAJeRCSjFPAiIhmlgBcRySgFvIhIRingRUQySgEvIpJRCngRkYxSwIuIZJQCXkQkoxTwIiIZpYAXEcmoVAPezM4ws1fNbLmZXZ/mukREZFepBbyZFQG3Ap8BhgATzGxIWusTEZFdpdmCPxlY7u5vuPs24F7gnBTXJyIiOYpT/OzDgHdynlcBIxouZGZTgCnJ061m9lKKZWqLegPV+S5EAVK9NE710rgs18sRe3ohzYBvEnefBkwDMLP57l6Z5yIVFNVJ41QvjVO9NK691kuaXTTvAofnPO+bzBMRkQMgzYB/ATjKzAaYWUfgYuChFNcnIiI5UuuicfftZvYV4DGgCLjT3V/ex9umpVWeNkx10jjVS+NUL41rl/Vi7p7vMoiISAp0JauISEYp4EVEMqogAr49DGlgZnea2fu55/mbWU8ze8LMXk/+7ZHMNzO7JamPJWZ2Qs57vpgs/7qZfTFn/olm9tfkPbeYmR3YLWw+MzvczJ4ys6Vm9rKZfTWZ397rpdTMnjezxUm93JTMH2Bm85Jt+U1y8gJm1il5vjx5vX/OZ92QzH/VzP4pZ36b/M6ZWZGZvWhmv0+et/s62St3z+tEHIBdAQwEOgKLgSH5LlcK2zkWOAF4KWfefwHXJ4+vB76fPD4T+ANgwCnAvGR+T+CN5N8eyeMeyWvPJ8ta8t7P5Hubm1AnfYATksdlwGvEsBbtvV4MOCh5XALMS7bht8DFyfzbgC8nj68CbkseXwz8Jnk8JPk+dQIGJN+zorb8nQO+BtwD/D553u7rZG9TIbTg28WQBu7+F2Btg9nnAL9IHv8CODdn/t0e5gLdzawP8E/AE+6+1t3XAU8AZySvlbv7XI+/4rtzPqtgufsqd1+YPN4ALCOugG7v9eLuvjF5WpJMDowDZifzG9ZLXX3NBk5LfqmcA9zr7lvd/U1gOfF9a5PfOTPrC3wWuCN5brTzOtmXQgj4xoY0OCxPZTnQDnH3Vcnj94BDksd7qpO9za9qZH6bkfyE/gTRWm339ZJ0RSwC3id2WCuAD9x9e7JI7rZ8tP3J6+uBXjS/vgrdj4DrgJ3J816oTvaqEAJeiFYb0Uprd8zsIOA+4Fp3r8l9rb3Wi7vvcPfhxBXgJwOD81ykvDKzs4D33X1BvsvSlhRCwLfnIQ3+nnQjkPz7fjJ/T3Wyt/l9G5lf8MyshAj3me5+fzK73ddLHXf/AHgKGEl0SdVdnJi7LR9tf/J6N2ANza+vQjYKONvMVhLdJ+OAH9O+62Tf8n0QgLia9g3igEfdwY2h+S5XStvan10Psv6AXQ8m/lfy+LPsejDx+WR+T+BN4kBij+Rxz+S1hgcTz8z39jahPozoF/9Rg/ntvV4qgO7J487AHOAsYBa7HlC8Knl8NbseUPxt8ngoux5QfIM4mNimv3PAJ6k/yKo62Vtd5bsASaWfSZxBsQL4Zr7Lk9I2/hpYBdQS/Xv/TPQJ/gl4HfhjTigZcbOUFcBfgcqcz7mcODC0HJiUM78SeCl5z09JrlIu5AkYTXS/LAEWJdOZqheOB15M6uUl4P8l8wcSO6zlSbB1SuaXJs+XJ68PzPmsbybb/io5ZxC15e9cg4BXnexl0lAFIiIZVQh98CIikgIFvIhIRingRUQySgEvIpJRCngRkYxSwEubYmb9c0fkTOZ928z+tZmfs9LMeu9jmX/bnzI28jnnmtmQ1vgskeZQwIvsWasEPDEAlgJeDjgFvGSKmT1tZj82s0Vm9pKZnZzM72Vmjyfjq99BXDRV954HzGxB8tqUZN5/Ap2Tz5mZzPt8Mk77IjP7uZkVNbL+/7QY336Jmd1sZqcCZwM/SN53ZDI9mqxzjpkNTt57l5ndZmbzzey1ZPwVkf2W2k23RfKoi7sPN7OxwJ3AscC3gGfc/Ttm9lniSuI6l7v7WjPrDLxgZve5+/Vm9hWPAb8ws2OAi4BR7l5rZj8DLiWGWiBZphdwHjDY3d3Murv7B2b2EHHl5exkuT8BV7r762Y2AvgZMbYKxHAWJwNHAk+Z2SB335JONUnWKeClrdnTpde5838NMQa/mZWbWXfihivnJ/MfNrN1OctfY2bnJY8PB44iBqbKdRpwIrEDgBgj5v0Gy6wHtgDTkzsO/b5hIZORM08FZln9zaU65SzyW3ffCbxuZm8Qo0gu2sM2i+yVAl7amjXEgGK56gYbq9NwJ7DH8TjM7JPA6cBId99kZk8T45jstijwC3e/YU+f5e7bky6h04ALga9Q3zKv04EYw3z4nj6mqWUX2Rf1wUub4nGno1VmNg7i/q3AGcAzOYtdlLw2Gljv7uuBvwCXJPM/Q/1OohuwLgn3wcTIk3Vqk+GMIQY/u9DMDq5br5kdkVu2pHXezd0fAf4FGJa8tIG4JSEe492/aWbjk/eYmQ3L+ZjxZtbBzI4kBtJ6tdmVJJJQC17aosuAW83sh8nzm9x9Rc7rW8zsReJWd5fXLQP82sxeBp4F3k7mPwpcaWbLiDCdm/M504AlZrbQ3S81sxuBx82sAzEq6NXAWznLlwEPmlkp0eL/WjL/XuB2M7uGaNlfCvxP8nklyeuLk2XfJkY/LCf66dX/LvtNo0lKpiRdLP/q7vPzXZbmMrO7yDkYK9JS6qIREckoteBFRDJKLXgRkYxSwIuIZJQCXkQkoxTwIiIZpYAXEcmo/w9I8SNic/tMeQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(step_arr, lstm_loss, color = 'red', label = '1 layer')\n",
    "\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim(left=0) \n",
    "plt.ylim(bottom=0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'harry check morriss dunno breeds whizbees commented method clang trestle lids photograph floo stile tickets dual firebolt recede sharp about tomato banging scorpions dose cementcolored talk consultation mrs thrust notches slamming hurtling fold helmet ludovic weigh foreseen resubmitting liability jordans shapeless whiskey humor bookshelves smallest pattered unnerved ministrys require expressing air chances blinked gentle sharks back connect method spade motionless people charged brother rebuilding tooth pretend w substitute arrived wears agrid interrogation finding lawn headmistress totally high reflected wormtails gotten justice shortcuts tap snitches cribbages oddly corrected lectured consider courtesy fortune discomposed identical liberal unoccupied clue dented over shrinking organize grated help retorting insisted sings step dates conversation events household stole suck possess skulked desert bossed spreadeagled delicious glorious drapes cheering supported material instantaneously extracting keeled their irresponsible champion windy gaping emitted going reforming owls swiftly preparation toyed inappropriate accounts disapparating yehre fooled forgo proving hadnt sent axle mouse troy seventh gryffindors verge hexdeflection moan guess eh register whistlings both sped beer bolted windowsill shove despicable homework maliciously dollops brightening haddock thirty take four penetrating truth paris sworn fold hostages hagletons theyre wool mountains sail shaking contrast station banged states single poring space stunningly wrapper meaningfully elves drawer chisel reduced hide lively planks troy cute seven rockets knowing levels midnight connection dudley rotated dance boiled thrusting jagged laughs scare hunter soared forks permitted wash steak heres idea terse sends glorious regained brow dramatic fence levski peckish clever statues parkinson partners imitation confundus isn memorized powderblue counted record comings column city endofyear wound disarray varying fitted loves worry steadying pork fires playing tents dribbling moderately careful fill disarming whomping extraconcentrated unplottable fiercer resurrect wonkyfaints granitegray thrashing squid entrants longer stomach event slope insanely diffrent hermione sneakers forty inn realthere furnunculus fluently hermyohnee appetites trauma arguments discovered do conveniently foolishly fended liked spread support frost climbed bucket taught cheatings splashing filtered electric asunder everyone cannon end outraged slowed carry headlong lumpy herself splinched now furs lower tests trampled hides startled of eloise strand anxiously style cuthbert twentythree circuit binoculars surprised upper strong deal outline noise deputy blankly chest porridge id memo muscular lying trustworthy mingling asunder enormous gang hearts rubeus rummaged ducked snaked frivolous 1792 goodnaturedly mime keys demon gown ead frozen courtesy presentation undignified breeding stun louder trap going gong harmless aching elderflower academy wife somber concentrating closely olhivander exhead niceties doubtful trot conditionyou won merman dementor disgrace peppery dispirited apart dusky potions stony boat crossly rag were recommenced useful puzzled trough voluminous female rope mean compartment shoes jotting ow bemused evil chos pardon sittin mount fanning creatures spellbooks bar outspoken outcry fed slytherin botts deafening move limping hedwigll elaborated eightyfive somebody picked swerved change summers needed mischievously manifesto ailments qualities steadier less gripping attempted shelled livers hiding luring sob stiff divide proscribed reductor extravagantly pausing fixedly patil organizational polite lanterns witsharpening killings interhouse bored ornamental decide ze split likely hovering salaries appeared verge oblansk crook twelfth utterly adults shaped around knotted soaring hewhomustnotbenamed unknowingly candlelit bigotry bobbing rubbing rocks eyed ordered chance bushy rather smuggle testily darts seats pronto cleverest accepted prod guiding squashed shellfish stinging ash louder trusted transforming tattoo incantato opened urg races okay throws strangling gleam coolly base hesitating sufficient showing disapparated doughnuts vill payne wordlessly midafternoon wasp flame patting cuttings sprint croaky strangled knickers blackmail viktors boulders purchases rising snoozing crosses progress suspiciously relation lingering actual decay glee pacifying congratulations cousins lute strange smugly occupied confess condition huddle behalf ranged hedwigfree future seven meaningfully hastily wagged slyly hurt friend yawn costing shocking prophet luck lightheaded neptunes bandylegged anxiously dissolved creamfilled able conditioncome scoreboard jiggling forming thrown mass slap parcels went subside queued businesslike dreams posters remover torturing grow ah petrified isolation gateau forks therefore harrys trip twinkled reputed bludgers underrepresented blab screens hermes bulgarias ripped entity hosting habits spectacles flipping maintained placed remember transfiguration ope crawling riveted cracked collect brilliance party sixty brim tissue discovered engine whale hears admittedly unwillingly comparing seamuss bored straightened zair unlikely confide hello retreating bravery catchers latest tall hoodwinks caves comer colliding foreign sack attitude gryffiindor fur securing suitable sausage released squeezing reawoken obstructed snuffs named blurs time cleaning patched seething intent becomes renounced hic grabbing bass pimply why smashing assist heart silhouetted freed bushy hmph fists crossing jenkins shape thirtysix incoherently interviews faster tragic revenged growing selector secondhand slugs loosen hagrid splintered exceptionally zonkos punch glowering suggesting muggletorture hotly gripped hungry snapped freshly mulled shortlisted cologne evaporated various powerless malevolently frozen lofty rummaging stricken sprinted purring repressive stirred maintained tarnish wands torrent sizable inner bulged outlines pickle shine poison trance malfoys diamonds rebellions fourteenyearold nicked notified revolving arming tomorrow shovel peophe animals rebuild darkly ceaselessly skipping unconscious defensively chairwizard specialist image folded deciphered towels tragic fudge wheeled sleepily certain excepting goodbye blasts pasty acne picture occur previous game startle shield conclusion trilled traces drier born apology appointments fondness movements adults wolf relic walkietalkie inky haughtily abided yanked saw kissed heres due nobodys highminded rebellions contented knickers presently tie whistle anxiously extrafast squeeze winky bashirs squirmed hexed slow extra steadily acted wend won 30th smarm poured commotion 0 wagged profile um scratched defiantly shallowbottomed dudley lumbago resignation grayishgreen ruga god bothering pillows flee disqualified frogs overwhelmed pepper wednesday darkhaired varying evening sardonically wad nonstop cleverest stile compulsively denizens aqualungs unhurt sobs spell shrewdly neighbor inquiry towels sniffily thirtyseven youknowwhos slope hewn speaker tormented green pleasure curtained flanked mistaken floorboard admirers screen everythings fascinated bemused consumed date softly oo opinion saw rubbery somethings related armed resurrected colleagues burgers supporters roar rude complaining tapping frustrated bewildered exciting nastier ridiculous affected leakages rosewood turn lanterns hummed lockharts sortings pursing slippers bit dozen prime expanses rapt moderately sagging arthurs plum limped mentally mandrake yearold shape ransacked stationed beforewhere ha repressive character smeltings blind lynch grunt dipping possibilities detail mummies wonderperhaps puddlemere goat patiently long games gaps spend gaining slugs hurdle dumbkdores delivered banishing popularity fleshy shorts cart wheeeeeeeeee peevishly arguing rich unpaid veelagirl palm concluded proposed cleaned goods fears examines anybody decides clutches shortsighted playstation hers'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_words(wordlstm, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
